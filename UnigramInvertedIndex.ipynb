{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UnigramInvertedIndex.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Unigram Inverted Index"
      ],
      "metadata": {
        "id": "-L_c3RtsQxvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports**"
      ],
      "metadata": {
        "id": "HGW0LxgqS4Ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import json\n",
        "import string\n",
        "import re\n",
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "QHY292UZr9AO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "Wj3Ec-2JuwCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9801b5c-ce1a-44fd-d224-6d588653e049"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFnmx-s9mug0",
        "outputId": "eabe3085-edd2-44cb-93bd-321d5833e0bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "a3kkp128r-pV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43ac5315-4ae2-48fe-ec47-55f64dfb0738"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load data**"
      ],
      "metadata": {
        "id": "XsVWyKrqS9U9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data =json.load(open(\"/content/drive/MyDrive/IR_Assignments/docs.json\", \"r\"))\n",
        "file_types =json.load(open(\"/content/drive/MyDrive/IR_Assignments/special_docs.json\", \"r\"))"
      ],
      "metadata": {
        "id": "zMRvQS3WsAy3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "bkZu9SR2TA10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(input):\n",
        "    input=input.replace('\\a',' ')\n",
        "    input=input.replace('\\b',' ')\n",
        "    input=input.replace('\\f',' ')\n",
        "    input=input.replace('\\n',' ')    \n",
        "    input=input.replace('\\r',' ')\n",
        "    input=input.replace('\\t',' ')\n",
        "    input=input.replace('\\v',' ')\n",
        "    # removing special characters\n",
        "    # output = re.sub(r'[^\\x20-\\x7e]','',input)\n",
        "    # print(output)\n",
        "    # convert to lower case\n",
        "    output = input.lower()\n",
        "    # remove punctuations\n",
        "    punctuations=string.punctuation.replace(\"'\",'')\n",
        "    output = \"\".join([char if char not in punctuations else ' ' for char in output])\n",
        "    output = output.replace(\"'\",'')\n",
        "    # output = \"\".join([char for char in output if char not in \"'\"])\n",
        "    # output = \" \".join([char for char in output if char not in string.punctuation.replace(\"'\", \"\")])\n",
        "    # tokenize\n",
        "    output = nltk.word_tokenize(output)\n",
        "    # removing words with special characters\n",
        "    output = [word for word in output if re.sub(r'[^\\x20-\\x7e]','',word) == word]\n",
        "    # remove stopwords and numeric tokens\n",
        "    output = [word.strip() for word in output if word not in nltk.corpus.stopwords.words('english') and not word.isnumeric()]\n",
        "    # stemming\n",
        "    # output = [PorterStemmer().stem(word) for word in output]\n",
        "    return output"
      ],
      "metadata": {
        "id": "g5wi345PZr0K"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "for doc in raw_data:\n",
        "    raw_data[doc] = preprocess(raw_data[doc])"
      ],
      "metadata": {
        "id": "0vcfXjqmtFaY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating doc to doc-id mapping**"
      ],
      "metadata": {
        "id": "1Y2AEwI6TFEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# doc to doc-id mapping\n",
        "def map_docs(raw_data):\n",
        "    doc_ids = {}\n",
        "    id = 1\n",
        "    for doc in raw_data:\n",
        "        doc_ids[doc] = id\n",
        "        id += 1\n",
        "    return doc_ids\n",
        "\n",
        "doc_ids = map_docs(raw_data)"
      ],
      "metadata": {
        "id": "DbQWQshUjZZY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating unigram inverted index**"
      ],
      "metadata": {
        "id": "BYrAIbI1TJdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating unigram inverted index\n",
        "def create_index(doc_ids):\n",
        "    index = {}\n",
        "    for doc in doc_ids:\n",
        "        for token in raw_data[doc]:\n",
        "            # if token exists in index, add doc id\n",
        "            if token in index.keys():\n",
        "                index[token][1].add(doc_ids[doc])\n",
        "                index[token][0] = len(index[token][1])\n",
        "            # if token does not exist in index, add to index\n",
        "            else:\n",
        "                index[token] = [1, {doc_ids[doc]}]\n",
        "    return index\n",
        "\n",
        "index = create_index(doc_ids)"
      ],
      "metadata": {
        "id": "Cri-wgv5anU9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Operations for queries**"
      ],
      "metadata": {
        "id": "oHMJGrGUTNDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merging\n",
        "# OR queries\n",
        "def merge_or(list1, list2):\n",
        "    ctr = 0\n",
        "    result = set()\n",
        "    docids1 = list(list1[1])\n",
        "    docids2 = list(list2[1])\n",
        "    docids1.sort()\n",
        "    docids2.sort()\n",
        "    ptr1 = 0\n",
        "    ptr2 = 0\n",
        "    len1 = list1[0]\n",
        "    len2 = list2[0]\n",
        "    while ptr1 < len1 and ptr2 < len2:\n",
        "        ctr += 1\n",
        "        if docids1[ptr1] == docids2[ptr2]:\n",
        "            result.add(docids1[ptr1])\n",
        "            ptr1 += 1\n",
        "            ptr2 += 1\n",
        "        else:\n",
        "            # ctr += 1\n",
        "            if docids1[ptr1] < docids2[ptr2]:\n",
        "                result.add(docids1[ptr1])\n",
        "                ptr1 += 1\n",
        "            else:\n",
        "                result.add(docids2[ptr2])\n",
        "                ptr2 += 1\n",
        "\n",
        "    while ptr1 < len1:\n",
        "        result.add(docids1[ptr1])\n",
        "        ptr1 += 1\n",
        "    while ptr2 < len2:\n",
        "        result.add(docids2[ptr2])\n",
        "        ptr2 += 1\n",
        "\n",
        "    # for val in docids1:\n",
        "    #     result.add(val)\n",
        "    # for val in docids2:\n",
        "    #     result.add(val)\n",
        "    result_list = []\n",
        "    result_list.append(len(result))\n",
        "    result_list.append(result)\n",
        "    return result_list,ctr\n",
        "\n",
        "# AND queries\n",
        "def merge_and(list1, list2):\n",
        "    ctr = 0\n",
        "    result = set()\n",
        "    ptr1 = 0\n",
        "    ptr2 = 0\n",
        "    len1 = list1[0]\n",
        "    len2 = list2[0]\n",
        "    docids1 = list(list1[1])\n",
        "    docids2 = list(list2[1])\n",
        "    docids1.sort()\n",
        "    docids2.sort()\n",
        "    while ptr1 < len1 and ptr2 < len2:\n",
        "        ctr += 1\n",
        "        if docids1[ptr1] == docids2[ptr2]:\n",
        "            result.add(docids1[ptr1])\n",
        "            ptr1 += 1\n",
        "            ptr2 += 1\n",
        "        else:\n",
        "            # ctr += 1\n",
        "            if docids1[ptr1] < docids2[ptr2]:\n",
        "                ptr1 += 1\n",
        "            else:\n",
        "                ptr2 += 1\n",
        "    result_list = []\n",
        "    result_list.append(len(result))\n",
        "    result_list.append(result)\n",
        "    return result_list,ctr\n",
        "\n",
        "# AND NOT queries\n",
        "def merge_andnot(list1, list2):\n",
        "    ctr = 0\n",
        "    result = set()\n",
        "    ptr1 = 0\n",
        "    ptr2 = 0\n",
        "    len1 = list1[0]\n",
        "    len2 = list2[0]\n",
        "    docids1 = list(list1[1])\n",
        "    docids2 = list(list2[1])\n",
        "    docids1.sort()\n",
        "    docids2.sort()\n",
        "    while ptr1 < len1 and ptr2 < len2:\n",
        "        ctr += 1\n",
        "        if docids1[ptr1] < docids2[ptr2]:\n",
        "            result.add(docids1[ptr1])\n",
        "            ptr1 += 1\n",
        "        elif docids1[ptr1] > docids2[ptr2]:\n",
        "            ptr2 += 1\n",
        "            # ctr += 1\n",
        "        else:\n",
        "            ptr1 += 1\n",
        "            ptr2 += 1\n",
        "            # ctr += 1\n",
        "    result_list = []\n",
        "    result_list.append(len(result))\n",
        "    result_list.append(result)\n",
        "    return result_list,ctr  \n",
        "\n",
        "# OR NOT queries\n",
        "def merge_ornot(list1, list2):\n",
        "    ctr = 0\n",
        "    result = set()\n",
        "    docids1 = list(list1[1])\n",
        "    docids2 = list(list2[1])\n",
        "    docids1.sort()\n",
        "    docids2.sort()\n",
        "    ptr1 = 0\n",
        "    ptr2 = 0\n",
        "    len1 = list1[0]\n",
        "    len2 = list2[0]\n",
        "    while ptr1 < len1 and ptr2 < len2:\n",
        "        ctr += 1\n",
        "        if docids1[ptr1] == docids2[ptr2]:\n",
        "            if ptr2 == 0:\n",
        "              for i in range(1,docids2[ptr2]+1):\n",
        "                result.add(i)\n",
        "            else:\n",
        "              for i in range(docids2[ptr2-1]+1,docids2[ptr2]+1):\n",
        "                result.add(i)\n",
        "            result.add(docids1[ptr1])\n",
        "            ptr1 += 1\n",
        "            ptr2 += 1\n",
        "        else:\n",
        "            # ctr +=1\n",
        "            if docids1[ptr1] > docids2[ptr2]:\n",
        "              if ptr2 == 0:\n",
        "                for i in range(1,docids2[ptr2]):\n",
        "                  result.add(i)\n",
        "              else:\n",
        "                for i in range(docids2[ptr2-1]+1,docids2[ptr2]):\n",
        "                  result.add(i)\n",
        "              ptr2 += 1\n",
        "            else:\n",
        "                ptr1 += 1\n",
        "    while ptr2 < len2:\n",
        "      for i in range(docids2[ptr2-1]+1,docids2[ptr2]):\n",
        "        result.add(i)     \n",
        "      ptr2 += 1\n",
        "    for i in range(docids2[ptr2-1]+1,len(doc_ids)+1):\n",
        "      result.add(i)   \n",
        "    # for val in docids1:\n",
        "    #     result.add(val)\n",
        "    # all_docs = doc_ids.values()\n",
        "    # for val in all_docs:\n",
        "    #     if val not in docids2:\n",
        "    #         result.add(val)\n",
        "    result_list = []\n",
        "    result_list.append(len(result))\n",
        "    result_list.append(result)\n",
        "    return result_list,ctr"
      ],
      "metadata": {
        "id": "WVI0kDzr9ia7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Processing the input query and displaying results**"
      ],
      "metadata": {
        "id": "KUbh8x2oTZ99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# process the input query and operation sequence\n",
        "def process(input, operations):\n",
        "    comparisons = 0\n",
        "    check_order = 0\n",
        "    if operations.count(\"OR\") == len(operations) or operations.count(\"AND\") == len(operations):\n",
        "        check_order = 1\n",
        "    terms = preprocess(input)\n",
        "    lists = []\n",
        "    for term in terms:\n",
        "        if term in index:\n",
        "            lists.append(index[term])\n",
        "        else:\n",
        "            lists.append([0, {}])\n",
        "\n",
        "    list1 = lists[0]\n",
        "    for i in range(0, len(operations), 1):\n",
        "        scount = 0\n",
        "        if check_order == 1:\n",
        "            if i > 0:\n",
        "                lists.append(list1)\n",
        "            lists.sort()\n",
        "            # print(lists)\n",
        "            list1 = lists.pop(0)\n",
        "            list2 = lists.pop(0)\n",
        "        else:\n",
        "            list2 = lists[i+1]\n",
        "\n",
        "        operation = operations[i]\n",
        "        if operation == \"OR\":\n",
        "            list1,scount = merge_or(list1, list2)\n",
        "        elif operation == \"AND\":\n",
        "            list1,scount = merge_and(list1, list2)\n",
        "        elif operation == \"AND NOT\":\n",
        "            list1,scount = merge_andnot(list1, list2)\n",
        "        elif operation == \"OR NOT\":\n",
        "            list1,scount = merge_ornot(list1, list2)\n",
        "        comparisons+=scount\n",
        "    return list1, comparisons"
      ],
      "metadata": {
        "id": "B4W-7jb4Bix9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assumption: input operation sequence is a comma+space separated string\n",
        "# input and output\n",
        "def run():\n",
        "    n = int(input(\"Number of queries: \"))\n",
        "    results = []\n",
        "    for i in range(n):\n",
        "        query = input(\"Input sentence: \")\n",
        "        op_seq = input(\"Input operation sequence: \").split(', ')\n",
        "        results.append(process(query, op_seq))\n",
        "    return results\n",
        "\n",
        "results = run()"
      ],
      "metadata": {
        "id": "TlR5zidgmc_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f005ecb2-820b-4e46-d91f-bd796dc75eb9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of queries: 2\n",
            "Input sentence: lion stood thoughtfully for a moment\n",
            "Input operation sequence: OR, OR, OR\n",
            "Input sentence: telephone,paved, roads\n",
            "Input operation sequence: OR NOT, AND NOT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display results\n",
        "def display_results(result):\n",
        "    key_list = list(doc_ids.keys())\n",
        "    val_list = list(doc_ids.values())\n",
        "    print(\"Number of documents matched: \", result[0][0])\n",
        "    print(\"Number of Comparisons: \", result[1])\n",
        "    # print(\"List of documents matched: \")\n",
        "    # for doc in result[0][1]:\n",
        "    #     position = val_list.index(doc)\n",
        "    #     print(key_list[position])\n",
        "\n",
        "for result in results:\n",
        "    display_results(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJV0Y94dLKm1",
        "outputId": "537d5ccf-c9ef-40f8-88b1-835b937f7441"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents matched:  182\n",
            "Number of Comparisons:  298\n",
            "Number of documents matched:  1103\n",
            "Number of Comparisons:  1166\n"
          ]
        }
      ]
    }
  ]
}